{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomemodelo = 'Light GBM'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caminhos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#Folder Inicial\n",
    "path = os.getcwd()\n",
    "\n",
    "#Subpastas\n",
    "pathin = path + '\\\\Entrada\\\\'\n",
    "pathfixo = path + '\\\\Fixo\\\\'\n",
    "pathout = path + '\\\\Saida\\\\'\n",
    "pathparcial = path + '\\\\Parcial\\\\'\n",
    "pathaux = path + '\\\\Auxiliar\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "import pickle\n",
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', 3000)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from time import gmtime, strftime\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.utils import parallel_backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20.3\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lendo a Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10877, 11)\n",
      "(3626, 11)\n"
     ]
    }
   ],
   "source": [
    "file = 'Treino'\n",
    "treino = pd.read_pickle(pathparcial + 'Arquivo1 ' + file + '.pkl')\n",
    "\n",
    "file = 'Teste'\n",
    "teste = pd.read_pickle(pathparcial + 'Arquivo1 ' + file + '.pkl')\n",
    "\n",
    "print(treino.shape)\n",
    "print(teste.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10877, 6)\n",
      "(3626, 6)\n"
     ]
    }
   ],
   "source": [
    "#Excluindo variaveis que nao serao usadas no modelo\n",
    "y = 'respostafinal'\n",
    "Xtr = treino[['texto', 'length', 'words', 'avg_word_length', 'min_word_length', 'max_word_length']]\n",
    "colunas = list(Xtr)\n",
    "\n",
    "with open(pathaux + 'Variaveis Modelo ' + nomemodelo + '.pickle', 'wb') as f:\n",
    "    dill.dump((colunas, y), f)\n",
    "\n",
    "Xte = teste[colunas]\n",
    "\n",
    "print(Xtr.shape)\n",
    "print(Xte.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nomemodelo = 'Light GBM'\n",
    "\n",
    "seed = 123\n",
    "\n",
    "parameters = {\n",
    "    'transformer__tfidf__max_features': [1000],\n",
    "    #'transformer__tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "    'transformer__tfidf__ngram_range': [(1, 1)],\n",
    "    'transformer__tfidf__max_df': [.6],\n",
    "    'transformer__tfidf__min_df': [20],\n",
    "    'clf__max_depth': [4, 5, -1],\n",
    "    'clf__bagging_fraction': [.7],\n",
    "    'clf__min_data_leaf': [20],\n",
    "    'clf__feature_fraction': [.7,],\n",
    "    'clf__boosting_type': ['gbdt'],\n",
    "    'clf__num_boost_round': [300],\n",
    "    'clf__learning_rate': [.01],\n",
    "    'clf__min_child_smaples': [20],\n",
    "    'clf__class_weight': ['balanced', None],\n",
    "    'clf__random_state': [seed]\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('transformer', ColumnTransformer([('tfidf', TfidfVectorizer(analyzer = 'word'), 'texto')], remainder = 'passthrough')),\n",
    "    ('clf', lgb.LGBMClassifier() )\n",
    "])\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits = 3, n_repeats = 1, random_state = seed)\n",
    "gs = GridSearchCV(pipeline, parameters, cv = cv, scoring = 'f1_macro', n_jobs = 3, verbose = 1, refit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-12 01:31:49\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend MultiprocessingBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  18 out of  18 | elapsed:   25.0s finished\n",
      "C:\\Users\\laran\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-12 01:33:08\n"
     ]
    }
   ],
   "source": [
    "#Rodando GridSearch\n",
    "print(strftime('%Y-%m-%d %H:%M:%S', gmtime()))\n",
    "\n",
    "with parallel_backend('multiprocessing'):\n",
    "    gs.fit(Xtr, treino[y])\n",
    "\n",
    "joblib.dump(gs, pathaux + 'Modelo ' + nomemodelo + '.pkl')\n",
    "\n",
    "print(strftime('%Y-%m-%d %H:%M:%S', gmtime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4296979721617831"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__bagging_fraction': 0.7,\n",
       " 'clf__boosting_type': 'gbdt',\n",
       " 'clf__class_weight': 'balanced',\n",
       " 'clf__feature_fraction': 0.7,\n",
       " 'clf__learning_rate': 0.01,\n",
       " 'clf__max_depth': 5,\n",
       " 'clf__min_child_smaples': 20,\n",
       " 'clf__min_data_leaf': 20,\n",
       " 'clf__num_boost_round': 300,\n",
       " 'clf__random_state': 123,\n",
       " 'transformer__tfidf__max_df': 0.6,\n",
       " 'transformer__tfidf__max_features': 1000,\n",
       " 'transformer__tfidf__min_df': 20,\n",
       " 'transformer__tfidf__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laran\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\laran\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\laran\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\laran\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\laran\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "cvresults = pd.DataFrame(gs.cv_results_)[[\n",
    " 'mean_test_score',\n",
    " 'mean_train_score',\n",
    " 'param_clf__max_depth',\n",
    " 'param_clf__bagging_fraction',\n",
    " 'param_clf__min_data_leaf',\n",
    " 'param_clf__feature_fraction',\n",
    " 'param_clf__boosting_type',\n",
    " 'param_clf__num_boost_round',\n",
    " 'param_clf__learning_rate',\n",
    " 'param_clf__min_child_smaples',\n",
    " 'param_clf__class_weight',\n",
    " 'param_transformer__tfidf__max_df',\n",
    " 'param_transformer__tfidf__max_features',\n",
    " 'param_transformer__tfidf__min_df',\n",
    " 'param_transformer__tfidf__ngram_range',\n",
    " 'std_test_score',\n",
    " 'std_train_score']]\n",
    "ha = list(cvresults)\n",
    "ha = [w.replace('param_clf__', '') for w in ha]\n",
    "ha = [w.replace('param_transformer__', '') for w in ha]\n",
    "cvresults.columns = ha\n",
    "cvresults.to_excel(pathout + 'Modelo ' + nomemodelo + ' Resultados GridSearch.xlsx', encoding = 'latin1', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>bagging_fraction</th>\n",
       "      <th>min_data_leaf</th>\n",
       "      <th>feature_fraction</th>\n",
       "      <th>boosting_type</th>\n",
       "      <th>num_boost_round</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>min_child_smaples</th>\n",
       "      <th>class_weight</th>\n",
       "      <th>tfidf__max_df</th>\n",
       "      <th>tfidf__max_features</th>\n",
       "      <th>tfidf__min_df</th>\n",
       "      <th>tfidf__ngram_range</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.422259</td>\n",
       "      <td>0.449601</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>300</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.014672</td>\n",
       "      <td>0.001832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.429698</td>\n",
       "      <td>0.455497</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>300</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.013734</td>\n",
       "      <td>0.001277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.420964</td>\n",
       "      <td>0.480571</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>300</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.011622</td>\n",
       "      <td>0.005924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.353935</td>\n",
       "      <td>0.365801</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>300</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.007432</td>\n",
       "      <td>0.012052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.362038</td>\n",
       "      <td>0.377660</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>300</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.007194</td>\n",
       "      <td>0.010598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.381858</td>\n",
       "      <td>0.420923</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>300</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.015490</td>\n",
       "      <td>0.007362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_test_score  mean_train_score max_depth bagging_fraction min_data_leaf  \\\n",
       "0         0.422259          0.449601         4              0.7            20   \n",
       "1         0.429698          0.455497         5              0.7            20   \n",
       "2         0.420964          0.480571        -1              0.7            20   \n",
       "3         0.353935          0.365801         4              0.7            20   \n",
       "4         0.362038          0.377660         5              0.7            20   \n",
       "5         0.381858          0.420923        -1              0.7            20   \n",
       "\n",
       "  feature_fraction boosting_type num_boost_round learning_rate  \\\n",
       "0              0.7          gbdt             300          0.01   \n",
       "1              0.7          gbdt             300          0.01   \n",
       "2              0.7          gbdt             300          0.01   \n",
       "3              0.7          gbdt             300          0.01   \n",
       "4              0.7          gbdt             300          0.01   \n",
       "5              0.7          gbdt             300          0.01   \n",
       "\n",
       "  min_child_smaples class_weight tfidf__max_df tfidf__max_features  \\\n",
       "0                20     balanced           0.6                1000   \n",
       "1                20     balanced           0.6                1000   \n",
       "2                20     balanced           0.6                1000   \n",
       "3                20         None           0.6                1000   \n",
       "4                20         None           0.6                1000   \n",
       "5                20         None           0.6                1000   \n",
       "\n",
       "  tfidf__min_df tfidf__ngram_range  std_test_score  std_train_score  \n",
       "0            20             (1, 1)        0.014672         0.001832  \n",
       "1            20             (1, 1)        0.013734         0.001277  \n",
       "2            20             (1, 1)        0.011622         0.005924  \n",
       "3            20             (1, 1)        0.007432         0.012052  \n",
       "4            20             (1, 1)        0.007194         0.010598  \n",
       "5            20             (1, 1)        0.015490         0.007362  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvresults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variaveis Importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_names_tfidf(X, column_tfidf, **params_tfidf):\n",
    "    tfidf = TfidfVectorizer(**params_tfidf)\n",
    "    tfidf.fit(X[column_tfidf])\n",
    "    tfidf_feature_names = {'tdidf__' + x for x in tfidf.get_feature_names()}\n",
    "    feature_names = list(tfidf_feature_names) + list(X.columns.drop(column_tfidf))\n",
    "    return feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurenames = feature_names_tfidf(X = Xtr, column_tfidf = 'texto',\n",
    "    max_df = list(gs.best_params_.values())[list(gs.best_params_).index('transformer__tfidf__max_df')],\n",
    "    min_df = list(gs.best_params_.values())[list(gs.best_params_).index('transformer__tfidf__min_df')],\n",
    "    max_features = list(gs.best_params_.values())[list(gs.best_params_).index('transformer__tfidf__max_features')],\n",
    "    ngram_range = list(gs.best_params_.values())[list(gs.best_params_).index('transformer__tfidf__ngram_range')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Feature_Importance(mod, nomemodelo, X, y, featurenames):\n",
    "    many = ['Linear SVM', 'Logistica', 'Naive Bayes']\n",
    "\n",
    "    k = mod.best_estimator_.named_steps['clf']\n",
    "\n",
    "    if nomemodelo in many:\n",
    "        #Logistica, SVM, Naive Bayes\n",
    "        Features = pd.DataFrame(k.coef_.tolist())\n",
    "        Features.columns = featurenames\n",
    "        if len(y.unique()) > 2:\n",
    "            Features.index = sorted(y.unique())\n",
    "    else:\n",
    "        #Arvores\n",
    "        Features = pd.DataFrame({'features': featurenames, 'value': k.feature_importances_.tolist()})\n",
    "        \n",
    "    Features.to_excel(pathout + 'Features ' + nomemodelo + '.xlsx', encoding = 'latin1', index = True)\n",
    "    \n",
    "Feature_Importance(mod = gs, nomemodelo = nomemodelo, X = Xtr, y = treino[y], featurenames = featurenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preditos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predtr = gs.best_estimator_.predict(Xtr)\n",
    "predte = gs.best_estimator_.predict(Xte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laran\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\laran\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\laran\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\laran\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "name = 'Treino'\n",
    "fim = treino[['ido', 'id', y]]\n",
    "fim['pred'] = predtr\n",
    "\n",
    "fim['Acertou'] = np.where(fim[y] == fim['pred'], 1, 0)\n",
    "fim.to_excel(pathout + 'Modelo ' + nomemodelo + ' Pred ' + name + '.xlsx', encoding = 'latin1', index = False)\n",
    "\n",
    "del fim\n",
    "\n",
    "name = 'Teste'\n",
    "fim = teste[['ido', 'id', y]]\n",
    "fim['pred'] = predte\n",
    "\n",
    "fim['Acertou'] = np.where(fim[y] == fim['pred'], 1, 0)\n",
    "fim.to_excel(pathout + 'Modelo ' + nomemodelo + ' Pred ' + name + '.xlsx', encoding = 'latin1', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
