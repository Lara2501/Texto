{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomemodelo = 'Light GBM'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caminhos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#Folder Inicial\n",
    "path = os.getcwd()\n",
    "\n",
    "#Subpastas\n",
    "pathin = path + '\\\\Entrada\\\\'\n",
    "pathfixo = path + '\\\\Fixo\\\\'\n",
    "pathout = path + '\\\\Saida\\\\'\n",
    "pathparcial = path + '\\\\Parcial\\\\'\n",
    "pathaux = path + '\\\\Auxiliar\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "import pickle\n",
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', 3000)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from time import gmtime, strftime\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.utils import parallel_backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20.3\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lendo Arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10877, 11)\n",
      "(3626, 11)\n"
     ]
    }
   ],
   "source": [
    "file = 'Treino'\n",
    "treino = pd.read_pickle(pathparcial + 'Arquivo1 ' + file + '.pkl')\n",
    "\n",
    "file = 'Teste'\n",
    "teste = pd.read_pickle(pathparcial + 'Arquivo1 ' + file + '.pkl')\n",
    "\n",
    "print(treino.shape)\n",
    "print(teste.shape)\n",
    "\n",
    "mod = joblib.load(pathaux + 'Modelo ' + nomemodelo + '.pkl')\n",
    "\n",
    "with open(pathaux + 'Variaveis Modelo ' + nomemodelo + '.pickle', 'rb') as f:\n",
    "    colunas = dill.load(f)\n",
    "    \n",
    "varx = list(colunas)[0]\n",
    "y = list(colunas)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variaveis Importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_names_tfidf(X, column_tfidf, **params_tfidf):\n",
    "    tfidf = TfidfVectorizer(**params_tfidf)\n",
    "    tfidf.fit(X[column_tfidf])\n",
    "    tfidf_feature_names = {'tdidf__' + x for x in tfidf.get_feature_names()}\n",
    "    feature_names = list(tfidf_feature_names) + list(X.columns.drop(column_tfidf))\n",
    "    return feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurenames = feature_names_tfidf(X = treino[varx], column_tfidf = 'texto',\n",
    "    max_df = list(mod.best_params_.values())[list(mod.best_params_).index('transformer__tfidf__max_df')],\n",
    "    min_df = list(mod.best_params_.values())[list(mod.best_params_).index('transformer__tfidf__min_df')],\n",
    "    max_features = list(mod.best_params_.values())[list(mod.best_params_).index('transformer__tfidf__max_features')],\n",
    "    ngram_range = list(mod.best_params_.values())[list(mod.best_params_).index('transformer__tfidf__ngram_range')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Feature_Importance(mod, nomemodelo, X, y, featurenames):\n",
    "    many = ['Linear SVM', 'Logistica', 'Naive Bayes']\n",
    "\n",
    "    k = mod.best_estimator_.named_steps['clf']\n",
    "\n",
    "    if nomemodelo in many:\n",
    "        #Logistica, SVM, Naive Bayes\n",
    "        Features = pd.DataFrame(k.coef_.tolist())\n",
    "        Features.columns = featurenames\n",
    "        if len(y.unique()) > 2:\n",
    "            Features.index = sorted(y.unique())\n",
    "    else:\n",
    "        #Arvores\n",
    "        Features = pd.DataFrame({'features': featurenames, 'value': k.feature_importances_.tolist()})\n",
    "        \n",
    "    Features.to_excel(pathout + 'Features 2 ' + nomemodelo + '.xlsx', encoding = 'latin1', index = True)\n",
    "    \n",
    "Feature_Importance(mod = mod, nomemodelo = nomemodelo, X = treino[varx], y = treino[y], featurenames = featurenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preditos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L000', 'L001', 'L002']\n",
      "['L000', 'L001', 'L002']\n",
      "['L000', 'L001', 'L002']\n"
     ]
    }
   ],
   "source": [
    "#Predito\n",
    "treino['pred'] = mod.best_estimator_.predict(treino[varx])\n",
    "teste['pred'] = mod.best_estimator_.predict(teste[varx])\n",
    "\n",
    "#Treino\n",
    "predtreino = treino['pred'] #Predito\n",
    "ytreino = treino[y]         #Real\n",
    "\n",
    "#Teste\n",
    "predteste = teste['pred'] #Predito\n",
    "yteste = teste[y]         #Real\n",
    "\n",
    "#Label\n",
    "label = sorted(ytreino.unique())\n",
    "\n",
    "labeltreino = sorted(pd.Series(ytreino.unique().tolist() + predtreino.unique().tolist()).unique())\n",
    "labelteste = sorted(pd.Series(yteste.unique().tolist() + predteste.unique().tolist()).unique())\n",
    "\n",
    "print(label)\n",
    "print(labeltreino)\n",
    "print(labelteste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(yreal, ypred, name, lab):\n",
    "    \n",
    "    ac = accuracy_score(y_true = yreal, y_pred = ypred).tolist()\n",
    "    #Comum\n",
    "    pr = precision_score(y_true = yreal, y_pred = ypred, average = None).tolist()\n",
    "    re = recall_score(y_true = yreal, y_pred = ypred, average = None).tolist()\n",
    "    f1 = f1_score(y_true = yreal, y_pred = ypred, average = None).tolist()\n",
    "    #Macro\n",
    "    prM = precision_score(y_true = yreal, y_pred = ypred, average = 'macro').tolist()\n",
    "    reM = recall_score(y_true = yreal, y_pred = ypred, average = 'macro').tolist()\n",
    "    f1M = f1_score(y_true = yreal, y_pred = ypred, average = 'macro').tolist()\n",
    "    #Weighted\n",
    "    prW = precision_score(y_true = yreal, y_pred = ypred, average = 'weighted').tolist()\n",
    "    reW = recall_score(y_true = yreal, y_pred = ypred, average = 'weighted').tolist()\n",
    "    f1W = f1_score(y_true = yreal, y_pred = ypred, average = 'weighted').tolist()\n",
    "\n",
    "    results = pd.DataFrame({\n",
    "        'Accuracy ' + name: ac,\n",
    "        'Precision ' + name: pr, 'Recall ' + name: re, 'F1 ' + name: f1, \n",
    "        'Precision Macro ' + name: pr, 'Recall Macro ' + name: re, 'F1 Macro ' + name: f1, \n",
    "        'Precision Weighted ' + name: pr, 'Recall Weighted ' + name: re, 'F1 Weighted ' + name: f1, \n",
    "    })\n",
    "\n",
    "    results['label'] = lab\n",
    "    \n",
    "    return results\n",
    "\n",
    "#Treino\n",
    "results_treino = results(yreal = ytreino, ypred = predtreino, name = 'Treino', lab = labeltreino)\n",
    "#Teste\n",
    "results_teste = results(yreal = yteste, ypred = predteste, name = 'Teste', lab = labeltreino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Juntando Resultados de Treino e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results_treino.merge(results_teste, left_on = results_treino['label'], right_on = results_teste['label'])\n",
    "results = results.drop(['label_x', 'label_y'], axis = 1)\n",
    "results.rename(columns = {'key_0': 'label'}, inplace = True)\n",
    "results = results.T\n",
    "results.to_excel(pathout + 'Resultados Treino Teste ' + nomemodelo + '.xlsx', encoding = 'latin1', index = True)\n",
    "#results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de Confusao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrizdeconfusao(yreal, ypred, label, name):\n",
    "    \n",
    "    #Precision\n",
    "    pr = precision_score(y_true = yreal, y_pred = ypred, average = None).tolist()\n",
    "    #Recall\n",
    "    re = recall_score(y_true = yreal, y_pred = ypred, average = None).tolist()\n",
    " \n",
    "    #Matriz de Confusao\n",
    "    cm = confusion_matrix(y_true = yreal, y_pred = ypred, sample_weight = None)\n",
    "    \n",
    "    #DataFrame\n",
    "    cm = pd.DataFrame(data = cm, index = label, columns = label)\n",
    "    \n",
    "    #Zero para NA\n",
    "    cm = cm.replace(0, np.nan)\n",
    "    \n",
    "    #Classses\n",
    "    names = list(cm)\n",
    "    \n",
    "    #Somando para ter TOTAL POR CLASSE\n",
    "    cm['NReal'] = cm.sum(axis = 1)\n",
    "    \n",
    "    #Calculando a soma das colunas = TOTAL PREDITO POR CLASSE\n",
    "    pp = pd.DataFrame(cm.sum(axis = 0)).transpose()\n",
    "    pp.index = ['NPred']\n",
    "    \n",
    "    #Adicionando linha com a soma das colunas = TOTAL PREDITO POR CLASSE\n",
    "    cm = cm.append(pp)\n",
    "    \n",
    "    #Linha de PRECISION\n",
    "    pp = pd.DataFrame(pr).transpose()\n",
    "    pp.index = ['Precision']\n",
    "    pp.columns = names\n",
    "    \n",
    "    cm = cm.append(pp, sort = False)\n",
    "    \n",
    "    #Coluna de Recall\n",
    "    pp = pd.DataFrame(re)\n",
    "    pp.columns = ['Recall']\n",
    "    pp.index = names\n",
    "    \n",
    "    cm = pd.merge(cm, pp, how = 'outer', left_index = True, right_index = True)\n",
    "    \n",
    "    cm.to_excel(pathout + 'Resultados MC ' + nomemodelo + ' ' + name + '.xlsx', encoding = 'latin1', index = True)\n",
    "    \n",
    "    return cm\n",
    "\n",
    "cmtr = matrizdeconfusao(yreal = ytreino, ypred = predtreino, label = labeltreino, name = 'Treino')\n",
    "cmte = matrizdeconfusao(yreal = yteste, ypred = predteste, label = labelteste, name = 'Teste')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L000</th>\n",
       "      <th>L001</th>\n",
       "      <th>L002</th>\n",
       "      <th>NReal</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>L000</th>\n",
       "      <td>4683.000000</td>\n",
       "      <td>1839.000000</td>\n",
       "      <td>295.0000</td>\n",
       "      <td>6817.0</td>\n",
       "      <td>0.686959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L001</th>\n",
       "      <td>1004.000000</td>\n",
       "      <td>1099.000000</td>\n",
       "      <td>202.0000</td>\n",
       "      <td>2305.0</td>\n",
       "      <td>0.476790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L002</th>\n",
       "      <td>788.000000</td>\n",
       "      <td>573.000000</td>\n",
       "      <td>394.0000</td>\n",
       "      <td>1755.0</td>\n",
       "      <td>0.224501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPred</th>\n",
       "      <td>6475.000000</td>\n",
       "      <td>3511.000000</td>\n",
       "      <td>891.0000</td>\n",
       "      <td>10877.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.723243</td>\n",
       "      <td>0.313016</td>\n",
       "      <td>0.4422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  L000         L001      L002    NReal    Recall\n",
       "L000       4683.000000  1839.000000  295.0000   6817.0  0.686959\n",
       "L001       1004.000000  1099.000000  202.0000   2305.0  0.476790\n",
       "L002        788.000000   573.000000  394.0000   1755.0  0.224501\n",
       "NPred      6475.000000  3511.000000  891.0000  10877.0       NaN\n",
       "Precision     0.723243     0.313016    0.4422      NaN       NaN"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmtr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L000</th>\n",
       "      <th>L001</th>\n",
       "      <th>L002</th>\n",
       "      <th>NReal</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>L000</th>\n",
       "      <td>1529.000000</td>\n",
       "      <td>637.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>2272.0</td>\n",
       "      <td>0.672975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L001</th>\n",
       "      <td>363.000000</td>\n",
       "      <td>341.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>769.0</td>\n",
       "      <td>0.443433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L002</th>\n",
       "      <td>299.000000</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>585.0</td>\n",
       "      <td>0.176068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPred</th>\n",
       "      <td>2191.000000</td>\n",
       "      <td>1161.000000</td>\n",
       "      <td>274.000000</td>\n",
       "      <td>3626.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.697855</td>\n",
       "      <td>0.293712</td>\n",
       "      <td>0.375912</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  L000         L001        L002   NReal    Recall\n",
       "L000       1529.000000   637.000000  106.000000  2272.0  0.672975\n",
       "L001        363.000000   341.000000   65.000000   769.0  0.443433\n",
       "L002        299.000000   183.000000  103.000000   585.0  0.176068\n",
       "NPred      2191.000000  1161.000000  274.000000  3626.0       NaN\n",
       "Precision     0.697855     0.293712    0.375912     NaN       NaN"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmte"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
