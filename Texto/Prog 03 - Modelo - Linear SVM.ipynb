{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomemodelo = 'Linear SVM'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caminhos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#Folder Inicial\n",
    "path = os.getcwd()\n",
    "\n",
    "#Subpastas\n",
    "pathin = path + '\\\\Entrada\\\\'\n",
    "pathfixo = path + '\\\\Fixo\\\\'\n",
    "pathout = path + '\\\\Saida\\\\'\n",
    "pathparcial = path + '\\\\Parcial\\\\'\n",
    "pathaux = path + '\\\\Auxiliar\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "import pickle\n",
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', 3000)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from time import gmtime, strftime\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.utils import parallel_backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20.3\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lendo a Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10877, 11)\n",
      "(3626, 11)\n"
     ]
    }
   ],
   "source": [
    "file = 'Treino'\n",
    "treino = pd.read_pickle(pathparcial + 'Arquivo1 ' + file + '.pkl')\n",
    "\n",
    "file = 'Teste'\n",
    "teste = pd.read_pickle(pathparcial + 'Arquivo1 ' + file + '.pkl')\n",
    "\n",
    "print(treino.shape)\n",
    "print(teste.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10877, 6)\n",
      "(3626, 6)\n"
     ]
    }
   ],
   "source": [
    "#Excluindo variaveis que nao serao usadas no modelo\n",
    "y = 'respostafinal'\n",
    "Xtr = treino[['texto', 'length', 'words', 'avg_word_length', 'min_word_length', 'max_word_length']]\n",
    "colunas = list(Xtr)\n",
    "\n",
    "with open(pathaux + 'Variaveis Modelo ' + nomemodelo + '.pickle', 'wb') as f:\n",
    "    dill.dump((colunas, y), f)\n",
    "\n",
    "Xte = teste[colunas]\n",
    "\n",
    "print(Xtr.shape)\n",
    "print(Xte.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nomemodelo = 'Linear SVM'\n",
    "\n",
    "seed = 123\n",
    "\n",
    "parameters = {\n",
    "    'transformer__tfidf__max_features': [2000, 3000],\n",
    "    #'transformer__tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "    'transformer__tfidf__ngram_range': [(1, 2)],\n",
    "    'transformer__tfidf__max_df': [.6],\n",
    "    'transformer__tfidf__min_df': [20],\n",
    "    #'clf__max_iter': [2000],\n",
    "    'clf__C': [1],\n",
    "    'clf__penalty': ['l2'],\n",
    "    'clf__fit_intercept': [True],\n",
    "    'clf__class_weight': ['balanced', None],\n",
    "    'clf__random_state': [seed]\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('transformer', ColumnTransformer([('tfidf', TfidfVectorizer(analyzer = 'word'), 'texto')], remainder = 'passthrough')),\n",
    "    ('clf', LinearSVC() )\n",
    "])\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits = 3, n_repeats = 1, random_state = seed)\n",
    "gs = GridSearchCV(pipeline, parameters, cv = cv, scoring = 'f1_macro', n_jobs = 3, verbose = 1, refit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-12 01:32:25\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend MultiprocessingBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  12 out of  12 | elapsed:   36.7s finished\n",
      "C:\\Users\\laran\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-12 01:33:19\n"
     ]
    }
   ],
   "source": [
    "#Rodando GridSearch\n",
    "print(strftime('%Y-%m-%d %H:%M:%S', gmtime()))\n",
    "\n",
    "with parallel_backend('multiprocessing'):\n",
    "    gs.fit(Xtr, treino[y])\n",
    "\n",
    "joblib.dump(gs, pathaux + 'Modelo ' + nomemodelo + '.pkl')\n",
    "\n",
    "print(strftime('%Y-%m-%d %H:%M:%S', gmtime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41943015108411624"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__C': 1,\n",
       " 'clf__class_weight': 'balanced',\n",
       " 'clf__fit_intercept': True,\n",
       " 'clf__penalty': 'l2',\n",
       " 'clf__random_state': 123,\n",
       " 'transformer__tfidf__max_df': 0.6,\n",
       " 'transformer__tfidf__max_features': 2000,\n",
       " 'transformer__tfidf__min_df': 20,\n",
       " 'transformer__tfidf__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laran\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\laran\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\laran\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\laran\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\laran\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "cvresults = pd.DataFrame(gs.cv_results_)[[\n",
    " 'mean_test_score',\n",
    " 'mean_train_score',\n",
    " 'param_clf__C',\n",
    " 'param_clf__class_weight',\n",
    " 'param_clf__fit_intercept',\n",
    " 'param_clf__penalty',\n",
    " 'param_transformer__tfidf__max_df',\n",
    " 'param_transformer__tfidf__max_features',\n",
    " 'param_transformer__tfidf__min_df',\n",
    " 'param_transformer__tfidf__ngram_range',\n",
    " 'std_test_score',\n",
    " 'std_train_score']]\n",
    "ha = list(cvresults)\n",
    "ha = [w.replace('param_clf__', '') for w in ha]\n",
    "ha = [w.replace('param_transformer__', '') for w in ha]\n",
    "cvresults.columns = ha\n",
    "cvresults.to_excel(pathout + 'Modelo ' + nomemodelo + ' Resultados GridSearch.xlsx', encoding = 'latin1', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>C</th>\n",
       "      <th>class_weight</th>\n",
       "      <th>fit_intercept</th>\n",
       "      <th>penalty</th>\n",
       "      <th>tfidf__max_df</th>\n",
       "      <th>tfidf__max_features</th>\n",
       "      <th>tfidf__min_df</th>\n",
       "      <th>tfidf__ngram_range</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.419430</td>\n",
       "      <td>0.431199</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2000</td>\n",
       "      <td>20</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.012424</td>\n",
       "      <td>0.002773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.419430</td>\n",
       "      <td>0.431199</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3000</td>\n",
       "      <td>20</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.012424</td>\n",
       "      <td>0.002773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.393838</td>\n",
       "      <td>0.398492</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2000</td>\n",
       "      <td>20</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.011620</td>\n",
       "      <td>0.001359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.393838</td>\n",
       "      <td>0.398492</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3000</td>\n",
       "      <td>20</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.011620</td>\n",
       "      <td>0.001359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_test_score  mean_train_score  C class_weight fit_intercept penalty  \\\n",
       "0         0.419430          0.431199  1     balanced          True      l2   \n",
       "1         0.419430          0.431199  1     balanced          True      l2   \n",
       "2         0.393838          0.398492  1         None          True      l2   \n",
       "3         0.393838          0.398492  1         None          True      l2   \n",
       "\n",
       "  tfidf__max_df tfidf__max_features tfidf__min_df tfidf__ngram_range  \\\n",
       "0           0.6                2000            20             (1, 2)   \n",
       "1           0.6                3000            20             (1, 2)   \n",
       "2           0.6                2000            20             (1, 2)   \n",
       "3           0.6                3000            20             (1, 2)   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "0        0.012424         0.002773  \n",
       "1        0.012424         0.002773  \n",
       "2        0.011620         0.001359  \n",
       "3        0.011620         0.001359  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvresults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variaveis Importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_names_tfidf(X, column_tfidf, **params_tfidf):\n",
    "    tfidf = TfidfVectorizer(**params_tfidf)\n",
    "    tfidf.fit(X[column_tfidf])\n",
    "    tfidf_feature_names = {'tdidf__' + x for x in tfidf.get_feature_names()}\n",
    "    feature_names = list(tfidf_feature_names) + list(X.columns.drop(column_tfidf))\n",
    "    return feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurenames = feature_names_tfidf(X = Xtr, column_tfidf = 'texto',\n",
    "    max_df = list(gs.best_params_.values())[list(gs.best_params_).index('transformer__tfidf__max_df')],\n",
    "    min_df = list(gs.best_params_.values())[list(gs.best_params_).index('transformer__tfidf__min_df')],\n",
    "    max_features = list(gs.best_params_.values())[list(gs.best_params_).index('transformer__tfidf__max_features')],\n",
    "    ngram_range = list(gs.best_params_.values())[list(gs.best_params_).index('transformer__tfidf__ngram_range')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Feature_Importance(mod, nomemodelo, X, y, featurenames):\n",
    "    many = ['Linear SVM', 'Logistica', 'Naive Bayes']\n",
    "\n",
    "    k = mod.best_estimator_.named_steps['clf']\n",
    "\n",
    "    if nomemodelo in many:\n",
    "        #Logistica, SVM, Naive Bayes\n",
    "        Features = pd.DataFrame(k.coef_.tolist())\n",
    "        Features.columns = featurenames\n",
    "        if len(y.unique()) > 2:\n",
    "            Features.index = sorted(y.unique())\n",
    "    else:\n",
    "        #Arvores\n",
    "        Features = pd.DataFrame({'features': featurenames, 'value': k.feature_importances_.tolist()})\n",
    "        \n",
    "    Features.to_excel(pathout + 'Features ' + nomemodelo + '.xlsx', encoding = 'latin1', index = True)\n",
    "    \n",
    "Feature_Importance(mod = gs, nomemodelo = nomemodelo, X = Xtr, y = treino[y], featurenames = featurenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preditos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predtr = gs.best_estimator_.predict(Xtr)\n",
    "predte = gs.best_estimator_.predict(Xte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laran\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\laran\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\laran\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\laran\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "name = 'Treino'\n",
    "fim = treino[['ido', 'id', y]]\n",
    "fim['pred'] = predtr\n",
    "\n",
    "fim['Acertou'] = np.where(fim[y] == fim['pred'], 1, 0)\n",
    "fim.to_excel(pathout + 'Modelo ' + nomemodelo + ' Pred ' + name + '.xlsx', encoding = 'latin1', index = False)\n",
    "\n",
    "del fim\n",
    "\n",
    "name = 'Teste'\n",
    "fim = teste[['ido', 'id', y]]\n",
    "fim['pred'] = predte\n",
    "\n",
    "fim['Acertou'] = np.where(fim[y] == fim['pred'], 1, 0)\n",
    "fim.to_excel(pathout + 'Modelo ' + nomemodelo + ' Pred ' + name + '.xlsx', encoding = 'latin1', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
